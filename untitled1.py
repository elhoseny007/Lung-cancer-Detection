# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/182tyMe7-AklaOZZ7iZlbG8Cumds4Q8oY
"""

from google.colab import drive
drive.mount('/content/drive')
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import collections
from sklearn.utils import shuffle
from sklearn.metrics import classification_report
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ------------------------------
# Settings
labels = ['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma']
image_size = 224
num_classes = len(labels)
base_path = "/content/drive/MyDrive/Lung Tumor "

# ------------------------------
# Image sharpening function
def sharpen_image(img):
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]])
    return cv2.filter2D(img, -1, kernel)

# ------------------------------
# Image blurring function
def blur_image(img):
    return cv2.GaussianBlur(img, (3, 3), 0)  # Reduced blur

# ------------------------------
# Contrast enhancement
def increase_contrast(img, alpha=1.2, beta=-0.5):
    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

# ------------------------------
# Crop using contour
def crop_with_contour(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        c = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(c)
        cropped = img[y:y+h, x:x+w]
        return cv2.resize(cropped, (image_size, image_size))
    return cv2.resize(img, (image_size, image_size))

# ------------------------------
# Visualize distribution
total_counts = collections.Counter()
for split in ['train', 'valid', 'test']:
    for label in labels:
        folder = os.path.join(base_path, split, label)
        count = len(os.listdir(folder))
        total_counts[label] += count
        print(f"{split}/{label}: {count} images")

plt.figure(figsize=(8, 6))
plt.bar(total_counts.keys(), total_counts.values(), color='skyblue')
plt.xlabel("Class")
plt.ylabel("Total Number of Images")
plt.title("Total Class Distribution (train + valid + test)")
plt.xticks(rotation=15)
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

# ------------------------------
# Load and preprocess dataset
def load_dataset(split):
    X, y = [], []
    for label in labels:
        folder = os.path.join(base_path, split, label)
        for fname in os.listdir(folder):
            img_path = os.path.join(folder, fname)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (image_size, image_size))
                img = sharpen_image(img)
                img = increase_contrast(img)
                img = blur_image(img)
                X.append(img)
                y.append(labels.index(label))
    return np.array(X, dtype=np.float32) / 255.0, to_categorical(np.array(y), num_classes=num_classes)

X_train, y_train = load_dataset('train')
X_val, y_val = load_dataset('valid')
X_test, y_test = load_dataset('test')

# ------------------------------
# Display example
def display_process_per_label(X, y, class_names):
    shown_classes = set()
    indices_to_show = {}

    # Convert one-hot encoded labels back to class indices
    y_labels = np.argmax(y, axis=1)

    # Find one index per class
    for i, label in enumerate(y_labels):
        if label not in shown_classes:
            indices_to_show[label] = i
            shown_classes.add(label)
        if len(shown_classes) == len(class_names):
            break

    # Display preprocessing pipeline for one sample per class
    for label, idx in indices_to_show.items():
        original = (X[idx] * 255).astype(np.uint8)
        cropped = crop_with_contour(original)
        sharpened = sharpen_image(cropped)
        contrasted = increase_contrast(sharpened)
        blurred = blur_image(contrasted)

        fig, axs = plt.subplots(1, 5, figsize=(25, 5))
        axs[0].imshow(original)
        axs[0].set_title(f'{class_names[label]} - Original')
        axs[1].imshow(cropped)
        axs[1].set_title('Cropped')
        axs[2].imshow(sharpened)
        axs[2].set_title('Sharpened')
        axs[3].imshow(contrasted)
        axs[3].set_title('Sharpened + Contrast')
        axs[4].imshow(blurred)
        axs[4].set_title('Sharpened + Contrast + Blurred')
        for ax in axs:
            ax.axis('off')
        plt.tight_layout()
        plt.show()
display_process_per_label(X_train, y_train, labels)


# ------------------------------
# VGG16 Model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
])

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ------------------------------
# Callbacks
callbacks = [
    ModelCheckpoint('/content/drive/MyDrive/Lung Tumor/best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1, min_lr=0.000001),
    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1, mode='max')
]

# ------------------------------
# Train the model
history = model.fit(
    X_train, y_train,
    batch_size=32,
    validation_data=(X_val, y_val),
    epochs=15,
    callbacks=callbacks
)

# ------------------------------
# Evaluate
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")

# ------------------------------
# Training graphs
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

plt.figure()
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

# ------------------------------
# Classification Report
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test, axis=1)
print(classification_report(true_classes, predicted_classes, target_names=labels))

# ------------------------------
# Save model
model.save('/content/drive/MyDrive/Lung Tumor/model_vgg16_layer_ver2.h5')